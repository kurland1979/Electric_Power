import os
import pickle
import matplotlib.pyplot as plt 
import pandas as pd
import numpy as np
from random_forest import build_random_pipeline
from model_xgboost import build_xgboost_pipeline
from linear_regression import split_X_y
from model_naive_forecast import split_train_test
from feature_engineering import consumption_pipeline
from data_preprocessing import data_pipeline


def loading_files():
    """
    Loads saved model results from pickle files before and after moving average feature engineering.
    
    Returns:
        tuple: 
            data_before (dict): Model results loaded from 'results_before_MA.pkl'.
            data_after (dict): Model results loaded from 'results_after_MA.pkl'.
    
    Notes:
        - If one of the files does not exist, prints a message and that value will be undefined.
        - Files are expected to be dictionaries saved as pickle objects.
    """
    
    if os.path.exists('results_before_MA.pkl'):
        with open('results_before_MA.pkl', 'rb') as f:
            data_before = pickle.load(f)
    else:
        print('File does not exist')
            
    if os.path.exists('results_after_MA.pkl'):
        with open('results_after_MA.pkl', 'rb') as f:
            data_after = pickle.load(f)
    else: 
        print('File does not exist')
        
    return data_before, data_after
        
def index_comparison_table(data_before, data_after):
    """
    Combines model evaluation results from before and after feature engineering (e.g., rolling features)
    into a single DataFrame for comparison.

    Parameters:
        data_before (dict): Model results (e.g., MAE, RMSE, MAE_RATIO) before applying rolling features.
        data_after (dict): Model results after applying rolling features.

    Returns:
        pd.DataFrame: A DataFrame containing model names, version (before/after rolling), 
                      and all evaluation metrics for comparison.
    """
    
    df_before = pd.DataFrame(data_before).T
    df_before['Model'] = df_before.index
    df_before['Version'] = 'Before Rolling'
    
    df_after = pd.DataFrame(data_after).T
    df_after['Model'] = df_after.index
    df_after['Version'] = 'After Rolling'
    
    cols = ['Version', 'Model'] + [col for col in df_before.columns if col not in ['Model', 'Version']]
    all_df = pd.concat([df_before, df_after], ignore_index=True)[cols]
    
    return all_df

def index_comparison_plot(all_df):
    """
    Plots a bar chart comparing the MAE_RATIO metric of different models 
    before and after adding rolling features.

    Parameters:
        all_df (pd.DataFrame): DataFrame generated by index_comparison_table, 
                               containing 'Model_Version' and 'MAE_RATIO'.

    Returns:
        None
    """
    font1 = {'family':'serif','color':'blue','size':20}
    font2 = {'family':'serif','color':'darkred','size':15}
    
    all_df['Model_Version'] = all_df['Model'] + " - " + all_df['Version']
    x_labels = all_df['Model_Version']
    y_values = all_df['MAE_RATIO']
    
    
    plt.figure(figsize=(12,6))
    bars = plt.bar(x=x_labels, height=y_values, color='skyblue')
    plt.title("Model Comparison by MAE_RATIO", fontdict=font1)
    plt.xlabel('Model & Version', fontdict=font2)
    plt.ylabel('MAE_RATIO', fontdict=font2)
    plt.xticks(rotation=30, ha='right')

    for bar, value in zip(bars, y_values):
        plt.text(bar.get_x() + bar.get_width()/2, value + 0.1, f'{value:.2f}', 
                 ha='center', va='bottom', fontdict={'size':12})

    plt.tight_layout()
    plt.show()
    
def plot_feature_importance_comparison(rf_features, xgb_features, top_n=6):
    """
    Plots a grouped bar chart comparing feature importances 
    between RandomForest and XGB models.

    Parameters:
        rf_features (pd.DataFrame): 
            DataFrame of feature importances from RandomForest.
            Must contain columns ['Feature', 'Importance'].
        xgb_features (pd.DataFrame): 
            DataFrame of feature importances from XGB.
            Must contain columns ['Feature', 'Importance'].
        top_n (int, optional): 
            Number of top features to display (default is 6).

    Returns:
        None
    """
   
    
    top_rf = rf_features.head(top_n)
    top_xgb = xgb_features[xgb_features['Feature'].isin(top_rf['Feature'])]
    features = top_rf['Feature'].tolist()

    # Preparing the importance kit
    rf_importance = top_rf['Importance'].values
    xgb_importance = top_xgb.set_index('Feature').loc[features, 'Importance'].values

    # Positioning the columns
    x = np.arange(len(features))  
    width = 0.35  

    # Drawing the graph
    plt.figure(figsize=(10, 6))
    bars1 = plt.bar(x - width/2, rf_importance, width, label='RandomForest', color='skyblue')
    bars2 = plt.bar(x + width/2, xgb_importance, width, label='XGB', color='salmon')

    # Design
    plt.ylabel('Feature Importance', fontsize=14)
    plt.xlabel('Feature', fontsize=14)
    plt.title('Feature Importance by Model (RandomForest vs XGB)', fontsize=16)
    plt.xticks(x, features, rotation=20, ha='right')
    plt.legend(fontsize=13)

    # Adding a value above each column
    for bar in bars1:
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height()+0.01,
                 f'{bar.get_height():.2f}', ha='center', va='bottom', fontsize=11)
    for bar in bars2:
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height()+0.01,
                 f'{bar.get_height():.2f}', ha='center', va='bottom', fontsize=11)

    plt.tight_layout()
    plt.show()

    
    
def build_plot_pipeline():   

    data_before, data_after = loading_files()
    all_df = index_comparison_table(data_before, data_after)

    index_comparison_plot(all_df)
    df = data_pipeline()
    
    daily_df = consumption_pipeline(df,verbose=False)
    train, test = split_train_test(daily_df)
    X_train, y_train,X_test, y_test = split_X_y(train, test)
    result_random_forest, model_random_forest,rf_features = build_random_pipeline(X_train, y_train,X_test, y_test)
    result_xgboost, model_xgboost, xgb_features = build_xgboost_pipeline(X_train, y_train,X_test, y_test)
    plot_feature_importance_comparison(rf_features, xgb_features, top_n=6)    

            